{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "annoying-withdrawal",
   "metadata": {},
   "source": [
    "# tf.Dataset, batch, window, flat_map을 활용한 loader 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-project",
   "metadata": {},
   "source": [
    "### as_numpy_iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-alloy",
   "metadata": {},
   "source": [
    "### take"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-motion",
   "metadata": {},
   "source": [
    "### filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-gardening",
   "metadata": {},
   "source": [
    "### map\n",
    "\n",
    "- Dataset 전체에 함수를 맵핑합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-nirvana",
   "metadata": {},
   "source": [
    "### shuffle\n",
    "- 데이터세트는 buffer_size 요소로 버퍼를 채운 다음이 버퍼에서 요소를 무작위로 샘플링하여 선택한 요소를 새 요소로 바꿉니다.\n",
    "\n",
    "- 완벽한 셔플 링을 위해서는 데이터 세트의 전체 크기보다 크거나 같은 버퍼 크기가 필요합니다.\n",
    "\n",
    "- 예를 들어, 데이터 집합에 10,000 개의 element가 있지만 buffer_size가 1,000으로 설정된 경우 셔플은 처음에 버퍼의 처음 1,000 개 element 중 임의의 element 만 선택합니다.\n",
    "\n",
    "- element가 선택되면 버퍼의 공간이 다음 element (즉, 1,001-st)로 대체되어 1,000 element 버퍼를 유지합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-mailman",
   "metadata": {},
   "source": [
    "- 위 모든 것을 한 줄로 결합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-andrew",
   "metadata": {},
   "source": [
    "## batch, repeat  간의 관계 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-refund",
   "metadata": {},
   "source": [
    "### How `ds.repeat()` works\n",
    "\n",
    "- 반복할 때마다 데이터셋을 다시 초기화\n",
    "- element의 무한 시퀀스를 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-suicide",
   "metadata": {},
   "source": [
    "### What will `ds.repeat().batch()` produce  \n",
    "\n",
    "- 배치 전에 `ds.repeat()`가 있으므로 데이터 생성이 계속됩니다. 그러나 batch내 element의 순서는 `ds.random()`으로 인해 달라집니다. 고려해야 할 점은 랜덤 버퍼의 크기로 인해 6이 첫 번째 배치에 존재하지 않는다는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-amazon",
   "metadata": {},
   "source": [
    "## Image Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-tactics",
   "metadata": {},
   "source": [
    "- `list_files()` : file path를 Dataset으로 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-stanley",
   "metadata": {},
   "source": [
    "### train, test dataset 생성\n",
    "- train : test = 8 : 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-drinking",
   "metadata": {},
   "source": [
    "### image file을 읽고, folder 명을 label로 tuple return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-bandwidth",
   "metadata": {},
   "source": [
    "### scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-invasion",
   "metadata": {},
   "source": [
    "## window: Time Series 데이터셋 생성에 유용\n",
    "- window: 그룹화 할 윈도우 크기(갯수)  \n",
    "- drop_remainder: 남은 부분을 버릴지 살릴지 여부  \n",
    "- shift는 1 iteration당 몇 개씩 이동할 것인지  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-status",
   "metadata": {},
   "source": [
    "### drop_remainder=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-scroll",
   "metadata": {},
   "source": [
    "### shift=2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-disclosure",
   "metadata": {},
   "source": [
    "### `flat_map()`\n",
    "- dataset에 함수를 apply해주고, 결과를 flatten하게 펼쳐 줍니다.\n",
    "\n",
    "- 아래는 lambda 함수를 통해 3개의 batch를 읽어들인 뒤 flatten된 리턴값을 받습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-crossing",
   "metadata": {},
   "source": [
    "### `map()`\n",
    "- Time Series Dataset을 만드려는 경우, train/label 값을 분류하는 용도로 `map()`을 활용할 수 있습니다.\n",
    "\n",
    "- `x[:-1]`, `x[-1:]` 의 의도는 각 row의 마지막 index 전까지는 train data로, 마지막 index는 label로 활용하겠다는 의도입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-crossing",
   "metadata": {},
   "source": [
    "### 실습 예제: Sunspots 데이터셋을 활용하여 window_dataset 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-employment",
   "metadata": {},
   "source": [
    "각 row의 2번 index의 데이터를 우리가 time series 데이터로 만들어 보려고 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-platform",
   "metadata": {},
   "source": [
    "과거의 3일의 데이터를 보고 4일 째의 데이터를 예측해야한다라고 가정한다면,  \n",
    "window_size = 3 + 1 로 잡아줍니다.  \n",
    "3개는 train data의 갯수, 1은 label의 갯수입니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
