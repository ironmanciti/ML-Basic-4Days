{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c387e7ef",
   "metadata": {},
   "source": [
    "#  문장 내의 단어들을 임베딩\n",
    "- keras.layers.Embedding 레이어 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0db507fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "# 샘플 데이터: 간단한 문장들의 모음\n",
    "sentences = [\n",
    "    \"I love machine learning\",\n",
    "    \"I love coding in Python\",\n",
    "    \"Deep learning is fun\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dc90226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I': 1,\n",
       " 'love': 2,\n",
       " 'machine': 3,\n",
       " 'learning': 4,\n",
       " 'coding': 5,\n",
       " 'in': 6,\n",
       " 'Python': 7,\n",
       " 'Deep': 8,\n",
       " 'is': 9,\n",
       " 'fun': 10}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 문장을 단어로 분할하고, 각 단어에 대한 고유한 인덱스를 생성\n",
    "word_index = {}\n",
    "\n",
    "for sentence in sentences:\n",
    "    for word in sentence.split():\n",
    "        if word not in word_index:\n",
    "            word_index[word] = len(word_index) + 1\n",
    "            \n",
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98af754a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4], [1, 2, 5, 6, 7], [8, 4, 9, 10]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장들을 단어 인덱스의 시퀀스로 변환\n",
    "sequences = [[word_index[word] for word in sentence.split()] for sentence in sentences]\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51c37c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  0],\n",
       "       [ 1,  2,  5,  6,  7],\n",
       "       [ 8,  4,  9, 10,  0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장들 중 가장 긴 것의 길이를 구함\n",
    "max_length = max([len(seq) for seq in sequences])\n",
    "\n",
    "# 모든 문장을 가장 긴 문장의 길이로 패딩\n",
    "padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bddcd17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 8)\n",
      "tf.Tensor(\n",
      "[[[ 0.01964789  0.04982078 -0.00259792  0.01207108  0.00501344\n",
      "   -0.03558845  0.01545152  0.01110258]\n",
      "  [ 0.03608132 -0.02834145  0.01184057  0.03801778 -0.03405376\n",
      "   -0.03874751  0.02867026 -0.03788869]\n",
      "  [-0.02202942  0.03358087  0.0335927   0.03488762  0.00454522\n",
      "    0.04015798  0.03426404 -0.01249205]\n",
      "  [ 0.03454043  0.02845288  0.03782107 -0.04364526  0.03439027\n",
      "   -0.00610853 -0.02683942 -0.01086602]\n",
      "  [-0.02520714  0.03637946 -0.04417964  0.01727331 -0.02484065\n",
      "   -0.03742831  0.04018419 -0.01577323]]\n",
      "\n",
      " [[ 0.01964789  0.04982078 -0.00259792  0.01207108  0.00501344\n",
      "   -0.03558845  0.01545152  0.01110258]\n",
      "  [ 0.03608132 -0.02834145  0.01184057  0.03801778 -0.03405376\n",
      "   -0.03874751  0.02867026 -0.03788869]\n",
      "  [-0.03343445 -0.00361217 -0.01967759 -0.00299609 -0.03495841\n",
      "    0.02485074 -0.01322914 -0.02464907]\n",
      "  [ 0.00668986  0.00375447  0.02734328  0.00965524  0.00485077\n",
      "   -0.02006277 -0.04011371 -0.00481031]\n",
      "  [ 0.03586033 -0.03422767  0.04377914  0.02209132  0.00246817\n",
      "    0.04877276  0.02276179  0.00087597]]\n",
      "\n",
      " [[-0.01222767  0.04570584 -0.01642164 -0.03781677 -0.00629463\n",
      "   -0.01897699  0.01359895 -0.03158937]\n",
      "  [ 0.03454043  0.02845288  0.03782107 -0.04364526  0.03439027\n",
      "   -0.00610853 -0.02683942 -0.01086602]\n",
      "  [ 0.04962182 -0.01306261 -0.04645792 -0.04235701  0.01228185\n",
      "   -0.00997714 -0.01391023  0.03331753]\n",
      "  [ 0.00954638 -0.03247216  0.01955881  0.02164834  0.04768011\n",
      "    0.03900541  0.00110491 -0.01345045]\n",
      "  [-0.02520714  0.03637946 -0.04417964  0.01727331 -0.02484065\n",
      "   -0.03742831  0.04018419 -0.01577323]]], shape=(3, 5, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Embedding 레이어 생성\n",
    "embedding_dim = 8\n",
    "embedding_layer = Embedding(input_dim=len(word_index) + 1, output_dim=embedding_dim, input_length=max_length)\n",
    "\n",
    "# 패딩된 시퀀스를 Embedding 레이어에 통과시켜 임베딩된 결과를 얻음\n",
    "embedded_sequences = embedding_layer(padded_sequences)\n",
    "\n",
    "print(embedded_sequences.shape)\n",
    "print(embedded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "691a1486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Layer Shape : (11, 8)\n",
      "Embedding Layer Weights (Word Embeddings):\n",
      " [[-0.02520714  0.03637946 -0.04417964  0.01727331 -0.02484065 -0.03742831\n",
      "   0.04018419 -0.01577323]\n",
      " [ 0.01964789  0.04982078 -0.00259792  0.01207108  0.00501344 -0.03558845\n",
      "   0.01545152  0.01110258]\n",
      " [ 0.03608132 -0.02834145  0.01184057  0.03801778 -0.03405376 -0.03874751\n",
      "   0.02867026 -0.03788869]\n",
      " [-0.02202942  0.03358087  0.0335927   0.03488762  0.00454522  0.04015798\n",
      "   0.03426404 -0.01249205]\n",
      " [ 0.03454043  0.02845288  0.03782107 -0.04364526  0.03439027 -0.00610853\n",
      "  -0.02683942 -0.01086602]\n",
      " [-0.03343445 -0.00361217 -0.01967759 -0.00299609 -0.03495841  0.02485074\n",
      "  -0.01322914 -0.02464907]\n",
      " [ 0.00668986  0.00375447  0.02734328  0.00965524  0.00485077 -0.02006277\n",
      "  -0.04011371 -0.00481031]\n",
      " [ 0.03586033 -0.03422767  0.04377914  0.02209132  0.00246817  0.04877276\n",
      "   0.02276179  0.00087597]\n",
      " [-0.01222767  0.04570584 -0.01642164 -0.03781677 -0.00629463 -0.01897699\n",
      "   0.01359895 -0.03158937]\n",
      " [ 0.04962182 -0.01306261 -0.04645792 -0.04235701  0.01228185 -0.00997714\n",
      "  -0.01391023  0.03331753]\n",
      " [ 0.00954638 -0.03247216  0.01955881  0.02164834  0.04768011  0.03900541\n",
      "   0.00110491 -0.01345045]]\n",
      "\n",
      "\n",
      "Embedding for 'love':\n",
      " [ 0.03608132 -0.02834145  0.01184057  0.03801778 -0.03405376 -0.03874751\n",
      "  0.02867026 -0.03788869]\n"
     ]
    }
   ],
   "source": [
    "# Embedding 레이어의 가중치 (단어 임베딩 행렬) 출력\n",
    "embeddings = embedding_layer.get_weights()[0]\n",
    "print(\"Embedding Layer Shape :\", embeddings.shape)\n",
    "print(\"Embedding Layer Weights (Word Embeddings):\\n\", embeddings)\n",
    "print()\n",
    "\n",
    "# 예: 'love'라는 단어의 임베딩 벡터를 출력\n",
    "print(\"\\nEmbedding for 'love':\\n\", embeddings[word_index['love']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf45463",
   "metadata": {},
   "source": [
    "0은 보통 패딩을 나타내는 인덱스로 사용됩니다. 결과적으로, Embedding 레이어의 가중치 행렬의 크기는 (고유한 단어 수 + 1, 임베딩 벡터의 차원수)가 되므로, (11, 8)이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0718544",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
